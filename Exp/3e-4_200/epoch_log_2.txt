Total training samples: 22
Epoch [1/200], Loss: 1.1472
Epoch [2/200], Loss: 0.6977
Epoch [3/200], Loss: 0.6426
Epoch [4/200], Loss: 0.7718
Epoch [5/200], Loss: 0.7391
Epoch [6/200], Loss: 0.4948
Epoch [7/200], Loss: 0.5063
Epoch [8/200], Loss: 0.5305
Epoch [9/200], Loss: 0.6278
Epoch [10/200], Loss: 0.6144
Epoch [11/200], Loss: 0.5062
Epoch [12/200], Loss: 0.7236
Epoch [13/200], Loss: 0.5424
Epoch [14/200], Loss: 0.5981
Epoch [15/200], Loss: 0.6239
Epoch [16/200], Loss: 0.7309
Epoch [17/200], Loss: 0.5108
Epoch [18/200], Loss: 0.5418
Epoch [19/200], Loss: 0.6318
Epoch [20/200], Loss: 0.5846
Epoch [21/200], Loss: 0.5756
Epoch [22/200], Loss: 0.6096
Epoch [23/200], Loss: 0.4919
Epoch [24/200], Loss: 0.6169
Epoch [25/200], Loss: 0.5505
Epoch [26/200], Loss: 0.5317
Epoch [27/200], Loss: 0.8799
Epoch [28/200], Loss: 0.5716
Epoch [29/200], Loss: 0.6497
Epoch [30/200], Loss: 0.6387
Epoch [31/200], Loss: 0.5970
Epoch [32/200], Loss: 0.6348
Epoch [33/200], Loss: 0.6816
Epoch [34/200], Loss: 0.6114
Epoch [35/200], Loss: 0.5618
Epoch [36/200], Loss: 0.5594
Epoch [37/200], Loss: 0.5718
Epoch [38/200], Loss: 0.5447
Epoch [39/200], Loss: 0.6479
Epoch [40/200], Loss: 0.8329
Epoch [41/200], Loss: 0.6034
Epoch [42/200], Loss: 0.5965
Epoch [43/200], Loss: 0.5741
Epoch [44/200], Loss: 0.5274
Epoch [45/200], Loss: 0.4976
Epoch [46/200], Loss: 0.5280
Epoch [47/200], Loss: 0.6360
Epoch [48/200], Loss: 0.5041
Epoch [49/200], Loss: 0.5144
Epoch [50/200], Loss: 0.5597
Epoch [51/200], Loss: 0.6215
Epoch [52/200], Loss: 0.5201
Epoch [53/200], Loss: 0.4598
Epoch [54/200], Loss: 0.5618
Epoch [55/200], Loss: 0.4887
Epoch [56/200], Loss: 0.4731
Epoch [57/200], Loss: 0.4556
Epoch [58/200], Loss: 0.4336
Epoch [59/200], Loss: 0.6415
Epoch [60/200], Loss: 0.3775
Epoch [61/200], Loss: 0.5575
Epoch [62/200], Loss: 0.4738
Epoch [63/200], Loss: 0.5890
Epoch [64/200], Loss: 0.6391
Epoch [65/200], Loss: 0.3800
Epoch [66/200], Loss: 0.4311
Epoch [67/200], Loss: 0.6724
Epoch [68/200], Loss: 0.4909
Epoch [69/200], Loss: 0.5031
Epoch [70/200], Loss: 0.4532
Epoch [71/200], Loss: 0.4217
Epoch [72/200], Loss: 0.4693
Epoch [73/200], Loss: 0.6329
Epoch [74/200], Loss: 0.5642
Epoch [75/200], Loss: 0.5458
Epoch [76/200], Loss: 0.5972
Epoch [77/200], Loss: 0.6430
Epoch [78/200], Loss: 0.7324
Epoch [79/200], Loss: 0.5751
Epoch [80/200], Loss: 0.5109
Epoch [81/200], Loss: 0.4265
Epoch [82/200], Loss: 0.4356
Epoch [83/200], Loss: 0.5873
Epoch [84/200], Loss: 0.6344
Epoch [85/200], Loss: 0.5000
Epoch [86/200], Loss: 0.4481
Epoch [87/200], Loss: 0.5709
Epoch [88/200], Loss: 0.6553
Epoch [89/200], Loss: 0.4681
Epoch [90/200], Loss: 0.4836
Epoch [91/200], Loss: 0.4460
Epoch [92/200], Loss: 0.3967
Epoch [93/200], Loss: 0.5351
Epoch [94/200], Loss: 0.4264
Epoch [95/200], Loss: 0.7404
Epoch [96/200], Loss: 0.4682
Epoch [97/200], Loss: 0.8660
Epoch [98/200], Loss: 0.7219
Epoch [99/200], Loss: 0.6253
Epoch [100/200], Loss: 0.5617
Epoch [101/200], Loss: 0.6740
Epoch [102/200], Loss: 0.4219
Epoch [103/200], Loss: 0.4888
Epoch [104/200], Loss: 0.5313
Epoch [105/200], Loss: 0.4892
Epoch [106/200], Loss: 0.5876
Epoch [107/200], Loss: 0.4187
Epoch [108/200], Loss: 0.4798
Epoch [109/200], Loss: 0.7669
Epoch [110/200], Loss: 0.4761
Epoch [111/200], Loss: 0.3927
Epoch [112/200], Loss: 0.5025
Epoch [113/200], Loss: 0.5526
Epoch [114/200], Loss: 0.4423
Epoch [115/200], Loss: 0.6001
Epoch [116/200], Loss: 0.5723
Epoch [117/200], Loss: 0.5756
Epoch [118/200], Loss: 0.6822
Epoch [119/200], Loss: 0.4608
Epoch [120/200], Loss: 0.4835
Epoch [121/200], Loss: 0.5846
Epoch [122/200], Loss: 0.4988
Epoch [123/200], Loss: 0.4779
Epoch [124/200], Loss: 0.4724
Epoch [125/200], Loss: 0.5168
Epoch [126/200], Loss: 0.4769
Epoch [127/200], Loss: 0.4221
Epoch [128/200], Loss: 0.3698
Epoch [129/200], Loss: 0.6386
Epoch [130/200], Loss: 0.4919
Epoch [131/200], Loss: 0.5294
Epoch [132/200], Loss: 0.4697
Epoch [133/200], Loss: 0.5609
Epoch [134/200], Loss: 0.5796
Epoch [135/200], Loss: 0.5725
Epoch [136/200], Loss: 0.4241
Epoch [137/200], Loss: 0.5337
Epoch [138/200], Loss: 0.6124
Epoch [139/200], Loss: 0.4695
Epoch [140/200], Loss: 0.6539
Epoch [141/200], Loss: 0.5946
Epoch [142/200], Loss: 0.4560
Epoch [143/200], Loss: 0.7057
Epoch [144/200], Loss: 0.4158
Epoch [145/200], Loss: 0.4511
Epoch [146/200], Loss: 0.4605
Epoch [147/200], Loss: 0.5661
Epoch [148/200], Loss: 0.3813
Epoch [149/200], Loss: 0.4464
Epoch [150/200], Loss: 0.5055
Epoch [151/200], Loss: 0.5372
Epoch [152/200], Loss: 0.7906
Epoch [153/200], Loss: 0.6604
Epoch [154/200], Loss: 0.7347
Epoch [155/200], Loss: 0.6282
Epoch [156/200], Loss: 0.9130
Epoch [157/200], Loss: 0.5102
Epoch [158/200], Loss: 0.6950
Epoch [159/200], Loss: 0.7263
Epoch [160/200], Loss: 0.5690
Epoch [161/200], Loss: 0.6422
Epoch [162/200], Loss: 0.6412
Epoch [163/200], Loss: 0.5185
Epoch [164/200], Loss: 0.4261
Epoch [165/200], Loss: 0.6108
Epoch [166/200], Loss: 0.6924
Epoch [167/200], Loss: 0.4784
Epoch [168/200], Loss: 0.4560
Epoch [169/200], Loss: 0.5483
Epoch [170/200], Loss: 0.6327
Epoch [171/200], Loss: 0.4906
Epoch [172/200], Loss: 0.5302
Epoch [173/200], Loss: 0.4604
Epoch [174/200], Loss: 0.5308
Epoch [175/200], Loss: 0.5380
Epoch [176/200], Loss: 0.5375
Epoch [177/200], Loss: 0.4139
Epoch [178/200], Loss: 0.4091
Epoch [179/200], Loss: 0.4534
Epoch [180/200], Loss: 0.4542
Epoch [181/200], Loss: 0.4841
Epoch [182/200], Loss: 0.6874
Epoch [183/200], Loss: 0.3944
Epoch [184/200], Loss: 0.6158
Epoch [185/200], Loss: 0.4375
Epoch [186/200], Loss: 0.6831
Epoch [187/200], Loss: 0.7185
Epoch [188/200], Loss: 0.4602
Epoch [189/200], Loss: 0.4125
Epoch [190/200], Loss: 0.4975
Epoch [191/200], Loss: 0.5415
Epoch [192/200], Loss: 0.4827
Epoch [193/200], Loss: 0.4463
Epoch [194/200], Loss: 0.4192
Epoch [195/200], Loss: 0.6841
Epoch [196/200], Loss: 0.5315
Epoch [197/200], Loss: 0.6468
Epoch [198/200], Loss: 0.6717
Epoch [199/200], Loss: 0.4836
Epoch [200/200], Loss: 0.5659
Train class_to_idx: {'bus_stop_gym': 0, 'bus_stop_xiang_feng': 1, 'ntou_donut': 2, 'ntou_freedom_ship': 3}
Support set size: 12 samples
Query set size: 10 samples
Query 0: True = bus_stop_gym, Predicted = bus_stop_gym
Query 1: True = bus_stop_gym, Predicted = bus_stop_gym
Query 2: True = bus_stop_xiang_feng, Predicted = bus_stop_xiang_feng
Query 3: True = bus_stop_xiang_feng, Predicted = bus_stop_xiang_feng
Query 4: True = ntou_donut, Predicted = ntou_donut
Query 5: True = ntou_donut, Predicted = ntou_donut
Query 6: True = ntou_donut, Predicted = ntou_donut
Query 7: True = ntou_freedom_ship, Predicted = ntou_freedom_ship
Query 8: True = ntou_freedom_ship, Predicted = ntou_freedom_ship
Query 9: True = ntou_freedom_ship, Predicted = ntou_freedom_ship
Few-shot prototype classification accuracy: 1.00
GT: bus_stop_gym, Pred: bus_stop_gym
GT: bus_stop_xiang_feng, Pred: bus_stop_xiang_feng
GT: ntou_donut, Pred: ntou_donut
GT: ntou_freedom_ship, Pred: ntou_freedom_ship
Test accuracy: 1.00

[AutoEval] Running experiments for few_shot_k = 1 to 5

[AutoEval] --- Testing few_shot_k = 1 ---
→ Train acc = 0.72, Test acc = 0.75

[AutoEval] --- Testing few_shot_k = 2 ---
→ Train acc = 0.71, Test acc = 0.75

[AutoEval] --- Testing few_shot_k = 3 ---
→ Train acc = 0.70, Test acc = 0.75

[AutoEval] --- Testing few_shot_k = 4 ---
→ Train acc = 0.50, Test acc = 1.00

[AutoEval] --- Testing few_shot_k = 5 ---
→ Train acc = 0.50, Test acc = 1.00
