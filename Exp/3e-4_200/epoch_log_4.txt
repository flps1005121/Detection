Total training samples: 22
Epoch [1/200], Loss: 1.0057
Epoch [2/200], Loss: 0.7563
Epoch [3/200], Loss: 0.6921
Epoch [4/200], Loss: 0.6977
Epoch [5/200], Loss: 0.5790
Epoch [6/200], Loss: 0.6943
Epoch [7/200], Loss: 0.6132
Epoch [8/200], Loss: 0.6732
Epoch [9/200], Loss: 0.6365
Epoch [10/200], Loss: 0.6706
Epoch [11/200], Loss: 0.7870
Epoch [12/200], Loss: 0.6455
Epoch [13/200], Loss: 0.6636
Epoch [14/200], Loss: 0.6193
Epoch [15/200], Loss: 0.5321
Epoch [16/200], Loss: 0.9024
Epoch [17/200], Loss: 0.7624
Epoch [18/200], Loss: 0.5631
Epoch [19/200], Loss: 0.5388
Epoch [20/200], Loss: 0.8888
Epoch [21/200], Loss: 0.5930
Epoch [22/200], Loss: 0.7432
Epoch [23/200], Loss: 0.7795
Epoch [24/200], Loss: 0.7453
Epoch [25/200], Loss: 0.5721
Epoch [26/200], Loss: 0.5609
Epoch [27/200], Loss: 0.6428
Epoch [28/200], Loss: 0.5011
Epoch [29/200], Loss: 0.5462
Epoch [30/200], Loss: 0.6941
Epoch [31/200], Loss: 0.5758
Epoch [32/200], Loss: 0.4949
Epoch [33/200], Loss: 0.6503
Epoch [34/200], Loss: 0.5685
Epoch [35/200], Loss: 0.6184
Epoch [36/200], Loss: 0.6783
Epoch [37/200], Loss: 0.5125
Epoch [38/200], Loss: 0.5642
Epoch [39/200], Loss: 0.5528
Epoch [40/200], Loss: 0.5336
Epoch [41/200], Loss: 0.8710
Epoch [42/200], Loss: 0.4868
Epoch [43/200], Loss: 0.6368
Epoch [44/200], Loss: 0.8180
Epoch [45/200], Loss: 0.5939
Epoch [46/200], Loss: 0.4403
Epoch [47/200], Loss: 0.7059
Epoch [48/200], Loss: 0.6592
Epoch [49/200], Loss: 0.5146
Epoch [50/200], Loss: 0.5755
Epoch [51/200], Loss: 0.4641
Epoch [52/200], Loss: 0.5647
Epoch [53/200], Loss: 0.5518
Epoch [54/200], Loss: 0.6009
Epoch [55/200], Loss: 0.3825
Epoch [56/200], Loss: 0.5615
Epoch [57/200], Loss: 0.3919
Epoch [58/200], Loss: 0.6131
Epoch [59/200], Loss: 0.9418
Epoch [60/200], Loss: 0.6282
Epoch [61/200], Loss: 0.5232
Epoch [62/200], Loss: 0.5583
Epoch [63/200], Loss: 0.5935
Epoch [64/200], Loss: 0.6204
Epoch [65/200], Loss: 0.5727
Epoch [66/200], Loss: 0.5555
Epoch [67/200], Loss: 0.5834
Epoch [68/200], Loss: 0.5130
Epoch [69/200], Loss: 0.8335
Epoch [70/200], Loss: 0.6570
Epoch [71/200], Loss: 0.5041
Epoch [72/200], Loss: 0.6456
Epoch [73/200], Loss: 0.6471
Epoch [74/200], Loss: 0.4896
Epoch [75/200], Loss: 0.5457
Epoch [76/200], Loss: 0.4270
Epoch [77/200], Loss: 0.5584
Epoch [78/200], Loss: 0.4175
Epoch [79/200], Loss: 0.6997
Epoch [80/200], Loss: 0.4428
Epoch [81/200], Loss: 0.4438
Epoch [82/200], Loss: 0.5570
Epoch [83/200], Loss: 0.4346
Epoch [84/200], Loss: 0.4643
Epoch [85/200], Loss: 0.4410
Epoch [86/200], Loss: 0.5158
Epoch [87/200], Loss: 0.3995
Epoch [88/200], Loss: 0.4241
Epoch [89/200], Loss: 0.4302
Epoch [90/200], Loss: 0.4597
Epoch [91/200], Loss: 0.3578
Epoch [92/200], Loss: 0.4696
Epoch [93/200], Loss: 0.4959
Epoch [94/200], Loss: 0.5562
Epoch [95/200], Loss: 0.4184
Epoch [96/200], Loss: 0.6205
Epoch [97/200], Loss: 0.5234
Epoch [98/200], Loss: 0.5166
Epoch [99/200], Loss: 0.3770
Epoch [100/200], Loss: 0.4657
Epoch [101/200], Loss: 0.4534
Epoch [102/200], Loss: 0.4459
Epoch [103/200], Loss: 0.4376
Epoch [104/200], Loss: 0.4870
Epoch [105/200], Loss: 0.4748
Epoch [106/200], Loss: 0.4882
Epoch [107/200], Loss: 0.4438
Epoch [108/200], Loss: 0.4134
Epoch [109/200], Loss: 0.4770
Epoch [110/200], Loss: 0.6912
Epoch [111/200], Loss: 0.4467
Epoch [112/200], Loss: 0.4772
Epoch [113/200], Loss: 0.4981
Epoch [114/200], Loss: 0.4845
Epoch [115/200], Loss: 0.5116
Epoch [116/200], Loss: 0.5357
Epoch [117/200], Loss: 0.6376
Epoch [118/200], Loss: 0.7065
Epoch [119/200], Loss: 0.4856
Epoch [120/200], Loss: 0.5352
Epoch [121/200], Loss: 0.8153
Epoch [122/200], Loss: 0.5532
Epoch [123/200], Loss: 0.6084
Epoch [124/200], Loss: 0.3568
Epoch [125/200], Loss: 0.6062
Epoch [126/200], Loss: 0.5131
Epoch [127/200], Loss: 0.5043
Epoch [128/200], Loss: 0.5989
Epoch [129/200], Loss: 0.4621
Epoch [130/200], Loss: 0.5944
Epoch [131/200], Loss: 0.5226
Epoch [132/200], Loss: 0.4435
Epoch [133/200], Loss: 0.4581
Epoch [134/200], Loss: 0.4570
Epoch [135/200], Loss: 0.5902
Epoch [136/200], Loss: 0.5706
Epoch [137/200], Loss: 0.4015
Epoch [138/200], Loss: 0.4620
Epoch [139/200], Loss: 0.4939
Epoch [140/200], Loss: 0.4283
Epoch [141/200], Loss: 0.5367
Epoch [142/200], Loss: 0.4519
Epoch [143/200], Loss: 0.4477
Epoch [144/200], Loss: 0.3863
Epoch [145/200], Loss: 0.5276
Epoch [146/200], Loss: 0.4866
Epoch [147/200], Loss: 0.3899
Epoch [148/200], Loss: 0.3729
Epoch [149/200], Loss: 0.4421
Epoch [150/200], Loss: 0.3761
Epoch [151/200], Loss: 0.4508
Epoch [152/200], Loss: 0.4024
Epoch [153/200], Loss: 0.3783
Epoch [154/200], Loss: 0.4024
Epoch [155/200], Loss: 0.4637
Epoch [156/200], Loss: 0.4355
Epoch [157/200], Loss: 0.3908
Epoch [158/200], Loss: 0.4629
Epoch [159/200], Loss: 0.4851
Epoch [160/200], Loss: 0.4033
Epoch [161/200], Loss: 0.3461
Epoch [162/200], Loss: 0.4111
Epoch [163/200], Loss: 0.3820
Epoch [164/200], Loss: 0.3819
Epoch [165/200], Loss: 0.4633
Epoch [166/200], Loss: 0.3452
Epoch [167/200], Loss: 0.3515
Epoch [168/200], Loss: 0.4746
Epoch [169/200], Loss: 0.3713
Epoch [170/200], Loss: 0.3769
Epoch [171/200], Loss: 0.3902
Epoch [172/200], Loss: 0.3617
Epoch [173/200], Loss: 0.3479
Epoch [174/200], Loss: 0.4096
Epoch [175/200], Loss: 0.3570
Epoch [176/200], Loss: 0.4062
Epoch [177/200], Loss: 0.4406
Epoch [178/200], Loss: 0.3899
Epoch [179/200], Loss: 0.4516
Epoch [180/200], Loss: 0.5044
Epoch [181/200], Loss: 0.5288
Epoch [182/200], Loss: 0.4488
Epoch [183/200], Loss: 0.4049
Epoch [184/200], Loss: 0.4122
Epoch [185/200], Loss: 0.4360
Epoch [186/200], Loss: 0.4469
Epoch [187/200], Loss: 0.4252
Epoch [188/200], Loss: 0.6573
Epoch [189/200], Loss: 0.3805
Epoch [190/200], Loss: 0.4521
Epoch [191/200], Loss: 0.3868
Epoch [192/200], Loss: 0.4050
Epoch [193/200], Loss: 0.4496
Epoch [194/200], Loss: 0.4405
Epoch [195/200], Loss: 0.4347
Epoch [196/200], Loss: 0.3935
Epoch [197/200], Loss: 0.6851
Epoch [198/200], Loss: 0.5967
Epoch [199/200], Loss: 0.6325
Epoch [200/200], Loss: 0.4985
Train class_to_idx: {'bus_stop_gym': 0, 'bus_stop_xiang_feng': 1, 'ntou_donut': 2, 'ntou_freedom_ship': 3}
Support set size: 12 samples
Query set size: 10 samples
Query 0: True = bus_stop_gym, Predicted = bus_stop_gym
Query 1: True = bus_stop_gym, Predicted = bus_stop_xiang_feng
Query 2: True = bus_stop_xiang_feng, Predicted = bus_stop_xiang_feng
Query 3: True = bus_stop_xiang_feng, Predicted = bus_stop_xiang_feng
Query 4: True = ntou_donut, Predicted = ntou_freedom_ship
Query 5: True = ntou_donut, Predicted = ntou_donut
Query 6: True = ntou_donut, Predicted = ntou_donut
Query 7: True = ntou_freedom_ship, Predicted = ntou_freedom_ship
Query 8: True = ntou_freedom_ship, Predicted = bus_stop_xiang_feng
Query 9: True = ntou_freedom_ship, Predicted = ntou_freedom_ship
Few-shot prototype classification accuracy: 0.70
GT: bus_stop_gym, Pred: bus_stop_xiang_feng
GT: bus_stop_xiang_feng, Pred: ntou_freedom_ship
GT: ntou_donut, Pred: ntou_donut
GT: ntou_freedom_ship, Pred: ntou_freedom_ship
Test accuracy: 0.50

[AutoEval] Running experiments for few_shot_k = 1 to 5

[AutoEval] --- Testing few_shot_k = 1 ---
→ Train acc = 0.78, Test acc = 0.75

[AutoEval] --- Testing few_shot_k = 2 ---
→ Train acc = 0.64, Test acc = 0.75

[AutoEval] --- Testing few_shot_k = 3 ---
→ Train acc = 0.80, Test acc = 0.75

[AutoEval] --- Testing few_shot_k = 4 ---
→ Train acc = 0.83, Test acc = 1.00

[AutoEval] --- Testing few_shot_k = 5 ---
→ Train acc = 1.00, Test acc = 1.00
