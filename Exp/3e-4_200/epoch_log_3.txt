Total training samples: 22
Epoch [1/200], Loss: 1.1919
Epoch [2/200], Loss: 0.7363
Epoch [3/200], Loss: 0.9614
Epoch [4/200], Loss: 0.7538
Epoch [5/200], Loss: 0.6319
Epoch [6/200], Loss: 0.7955
Epoch [7/200], Loss: 0.6392
Epoch [8/200], Loss: 0.7356
Epoch [9/200], Loss: 0.6497
Epoch [10/200], Loss: 0.6395
Epoch [11/200], Loss: 0.6105
Epoch [12/200], Loss: 0.6772
Epoch [13/200], Loss: 0.5357
Epoch [14/200], Loss: 0.5882
Epoch [15/200], Loss: 0.5449
Epoch [16/200], Loss: 0.6530
Epoch [17/200], Loss: 0.6414
Epoch [18/200], Loss: 0.5221
Epoch [19/200], Loss: 0.5698
Epoch [20/200], Loss: 0.4363
Epoch [21/200], Loss: 0.4584
Epoch [22/200], Loss: 0.5935
Epoch [23/200], Loss: 0.5534
Epoch [24/200], Loss: 1.1682
Epoch [25/200], Loss: 0.8056
Epoch [26/200], Loss: 0.5848
Epoch [27/200], Loss: 0.7048
Epoch [28/200], Loss: 0.6639
Epoch [29/200], Loss: 0.7477
Epoch [30/200], Loss: 0.5855
Epoch [31/200], Loss: 0.4957
Epoch [32/200], Loss: 0.5822
Epoch [33/200], Loss: 0.6454
Epoch [34/200], Loss: 0.7663
Epoch [35/200], Loss: 0.5858
Epoch [36/200], Loss: 0.6921
Epoch [37/200], Loss: 0.5652
Epoch [38/200], Loss: 0.5081
Epoch [39/200], Loss: 0.5828
Epoch [40/200], Loss: 0.7091
Epoch [41/200], Loss: 0.5454
Epoch [42/200], Loss: 0.4789
Epoch [43/200], Loss: 0.4748
Epoch [44/200], Loss: 0.4397
Epoch [45/200], Loss: 0.5434
Epoch [46/200], Loss: 0.4688
Epoch [47/200], Loss: 0.6413
Epoch [48/200], Loss: 0.5177
Epoch [49/200], Loss: 0.4381
Epoch [50/200], Loss: 0.6553
Epoch [51/200], Loss: 0.6099
Epoch [52/200], Loss: 0.7553
Epoch [53/200], Loss: 0.7362
Epoch [54/200], Loss: 0.7392
Epoch [55/200], Loss: 0.6760
Epoch [56/200], Loss: 1.1884
Epoch [57/200], Loss: 0.6066
Epoch [58/200], Loss: 0.8722
Epoch [59/200], Loss: 0.6671
Epoch [60/200], Loss: 0.4411
Epoch [61/200], Loss: 0.5066
Epoch [62/200], Loss: 0.4289
Epoch [63/200], Loss: 0.6288
Epoch [64/200], Loss: 0.4992
Epoch [65/200], Loss: 0.4580
Epoch [66/200], Loss: 0.5488
Epoch [67/200], Loss: 0.5092
Epoch [68/200], Loss: 0.4194
Epoch [69/200], Loss: 0.5932
Epoch [70/200], Loss: 0.4419
Epoch [71/200], Loss: 0.5936
Epoch [72/200], Loss: 0.4697
Epoch [73/200], Loss: 0.5481
Epoch [74/200], Loss: 0.7817
Epoch [75/200], Loss: 0.4438
Epoch [76/200], Loss: 0.5027
Epoch [77/200], Loss: 0.3945
Epoch [78/200], Loss: 0.6382
Epoch [79/200], Loss: 0.6612
Epoch [80/200], Loss: 0.5080
Epoch [81/200], Loss: 0.5828
Epoch [82/200], Loss: 0.4415
Epoch [83/200], Loss: 0.6926
Epoch [84/200], Loss: 0.3638
Epoch [85/200], Loss: 0.6359
Epoch [86/200], Loss: 0.5814
Epoch [87/200], Loss: 0.5168
Epoch [88/200], Loss: 0.4269
Epoch [89/200], Loss: 0.5162
Epoch [90/200], Loss: 0.4136
Epoch [91/200], Loss: 0.4866
Epoch [92/200], Loss: 0.3987
Epoch [93/200], Loss: 0.3943
Epoch [94/200], Loss: 0.4667
Epoch [95/200], Loss: 0.7469
Epoch [96/200], Loss: 0.4597
Epoch [97/200], Loss: 0.4934
Epoch [98/200], Loss: 0.5278
Epoch [99/200], Loss: 0.5577
Epoch [100/200], Loss: 0.6893
Epoch [101/200], Loss: 0.5111
Epoch [102/200], Loss: 0.6295
Epoch [103/200], Loss: 0.6357
Epoch [104/200], Loss: 0.5954
Epoch [105/200], Loss: 0.6908
Epoch [106/200], Loss: 0.7739
Epoch [107/200], Loss: 0.4254
Epoch [108/200], Loss: 0.5652
Epoch [109/200], Loss: 0.6267
Epoch [110/200], Loss: 0.6364
Epoch [111/200], Loss: 0.5584
Epoch [112/200], Loss: 0.4721
Epoch [113/200], Loss: 0.6038
Epoch [114/200], Loss: 0.5357
Epoch [115/200], Loss: 0.4124
Epoch [116/200], Loss: 0.4904
Epoch [117/200], Loss: 0.4231
Epoch [118/200], Loss: 0.3825
Epoch [119/200], Loss: 0.4504
Epoch [120/200], Loss: 0.4450
Epoch [121/200], Loss: 0.6732
Epoch [122/200], Loss: 0.3664
Epoch [123/200], Loss: 0.5272
Epoch [124/200], Loss: 0.4680
Epoch [125/200], Loss: 0.3968
Epoch [126/200], Loss: 0.5906
Epoch [127/200], Loss: 0.4621
Epoch [128/200], Loss: 0.4489
Epoch [129/200], Loss: 0.4875
Epoch [130/200], Loss: 0.6796
Epoch [131/200], Loss: 0.5786
Epoch [132/200], Loss: 0.7043
Epoch [133/200], Loss: 0.8033
Epoch [134/200], Loss: 0.4942
Epoch [135/200], Loss: 0.5574
Epoch [136/200], Loss: 0.4489
Epoch [137/200], Loss: 0.6889
Epoch [138/200], Loss: 0.4407
Epoch [139/200], Loss: 0.5308
Epoch [140/200], Loss: 0.6511
Epoch [141/200], Loss: 0.6111
Epoch [142/200], Loss: 0.4472
Epoch [143/200], Loss: 0.6721
Epoch [144/200], Loss: 0.6431
Epoch [145/200], Loss: 0.5481
Epoch [146/200], Loss: 0.4062
Epoch [147/200], Loss: 0.4494
Epoch [148/200], Loss: 0.5269
Epoch [149/200], Loss: 0.5637
Epoch [150/200], Loss: 0.4634
Epoch [151/200], Loss: 0.5113
Epoch [152/200], Loss: 0.5105
Epoch [153/200], Loss: 0.4640
Epoch [154/200], Loss: 0.4731
Epoch [155/200], Loss: 0.3703
Epoch [156/200], Loss: 0.8738
Epoch [157/200], Loss: 0.5318
Epoch [158/200], Loss: 0.7954
Epoch [159/200], Loss: 0.4477
Epoch [160/200], Loss: 0.4861
Epoch [161/200], Loss: 0.3731
Epoch [162/200], Loss: 0.5100
Epoch [163/200], Loss: 0.4816
Epoch [164/200], Loss: 0.4691
Epoch [165/200], Loss: 0.5969
Epoch [166/200], Loss: 0.5248
Epoch [167/200], Loss: 0.4677
Epoch [168/200], Loss: 0.4774
Epoch [169/200], Loss: 0.6043
Epoch [170/200], Loss: 0.5832
Epoch [171/200], Loss: 0.6589
Epoch [172/200], Loss: 0.5501
Epoch [173/200], Loss: 0.3944
Epoch [174/200], Loss: 0.5537
Epoch [175/200], Loss: 0.6191
Epoch [176/200], Loss: 0.3978
Epoch [177/200], Loss: 0.4993
Epoch [178/200], Loss: 0.5030
Epoch [179/200], Loss: 0.4568
Epoch [180/200], Loss: 0.6069
Epoch [181/200], Loss: 0.4118
Epoch [182/200], Loss: 0.6398
Epoch [183/200], Loss: 0.5242
Epoch [184/200], Loss: 0.5232
Epoch [185/200], Loss: 0.7066
Epoch [186/200], Loss: 0.3940
Epoch [187/200], Loss: 0.4240
Epoch [188/200], Loss: 0.8259
Epoch [189/200], Loss: 0.4731
Epoch [190/200], Loss: 0.5433
Epoch [191/200], Loss: 0.5219
Epoch [192/200], Loss: 0.4377
Epoch [193/200], Loss: 0.5674
Epoch [194/200], Loss: 0.4964
Epoch [195/200], Loss: 0.5912
Epoch [196/200], Loss: 0.5238
Epoch [197/200], Loss: 0.5119
Epoch [198/200], Loss: 0.5934
Epoch [199/200], Loss: 0.4628
Epoch [200/200], Loss: 0.4091
Train class_to_idx: {'bus_stop_gym': 0, 'bus_stop_xiang_feng': 1, 'ntou_donut': 2, 'ntou_freedom_ship': 3}
Support set size: 12 samples
Query set size: 10 samples
Query 0: True = bus_stop_gym, Predicted = bus_stop_gym
Query 1: True = bus_stop_gym, Predicted = bus_stop_gym
Query 2: True = bus_stop_xiang_feng, Predicted = bus_stop_xiang_feng
Query 3: True = bus_stop_xiang_feng, Predicted = bus_stop_xiang_feng
Query 4: True = ntou_donut, Predicted = ntou_donut
Query 5: True = ntou_donut, Predicted = ntou_donut
Query 6: True = ntou_donut, Predicted = ntou_donut
Query 7: True = ntou_freedom_ship, Predicted = ntou_freedom_ship
Query 8: True = ntou_freedom_ship, Predicted = ntou_donut
Query 9: True = ntou_freedom_ship, Predicted = ntou_freedom_ship
Few-shot prototype classification accuracy: 0.90
GT: bus_stop_gym, Pred: bus_stop_gym
GT: bus_stop_xiang_feng, Pred: bus_stop_xiang_feng
GT: ntou_donut, Pred: ntou_donut
GT: ntou_freedom_ship, Pred: ntou_freedom_ship
Test accuracy: 1.00

[AutoEval] Running experiments for few_shot_k = 1 to 5

[AutoEval] --- Testing few_shot_k = 1 ---
→ Train acc = 0.83, Test acc = 1.00

[AutoEval] --- Testing few_shot_k = 2 ---
→ Train acc = 0.71, Test acc = 1.00

[AutoEval] --- Testing few_shot_k = 3 ---
→ Train acc = 0.70, Test acc = 1.00

[AutoEval] --- Testing few_shot_k = 4 ---
→ Train acc = 0.83, Test acc = 1.00

[AutoEval] --- Testing few_shot_k = 5 ---
→ Train acc = 0.50, Test acc = 1.00
