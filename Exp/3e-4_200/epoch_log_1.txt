Total training samples: 22
Epoch [1/200], Loss: 1.2435
Epoch [2/200], Loss: 0.8157
Epoch [3/200], Loss: 0.9213
Epoch [4/200], Loss: 0.6599
Epoch [5/200], Loss: 0.7228
Epoch [6/200], Loss: 0.7014
Epoch [7/200], Loss: 0.6753
Epoch [8/200], Loss: 0.6319
Epoch [9/200], Loss: 0.5664
Epoch [10/200], Loss: 0.6174
Epoch [11/200], Loss: 0.7295
Epoch [12/200], Loss: 0.6080
Epoch [13/200], Loss: 0.5590
Epoch [14/200], Loss: 0.6769
Epoch [15/200], Loss: 0.7210
Epoch [16/200], Loss: 0.7676
Epoch [17/200], Loss: 0.6948
Epoch [18/200], Loss: 0.9816
Epoch [19/200], Loss: 0.4735
Epoch [20/200], Loss: 0.7608
Epoch [21/200], Loss: 0.5713
Epoch [22/200], Loss: 0.9616
Epoch [23/200], Loss: 0.5324
Epoch [24/200], Loss: 0.8475
Epoch [25/200], Loss: 0.7557
Epoch [26/200], Loss: 0.6027
Epoch [27/200], Loss: 0.7074
Epoch [28/200], Loss: 0.5681
Epoch [29/200], Loss: 1.0158
Epoch [30/200], Loss: 0.9870
Epoch [31/200], Loss: 0.8799
Epoch [32/200], Loss: 0.6848
Epoch [33/200], Loss: 0.5710
Epoch [34/200], Loss: 0.5714
Epoch [35/200], Loss: 0.4974
Epoch [36/200], Loss: 0.5470
Epoch [37/200], Loss: 0.5103
Epoch [38/200], Loss: 0.4810
Epoch [39/200], Loss: 0.5384
Epoch [40/200], Loss: 0.6404
Epoch [41/200], Loss: 1.0496
Epoch [42/200], Loss: 0.4717
Epoch [43/200], Loss: 0.5324
Epoch [44/200], Loss: 0.4950
Epoch [45/200], Loss: 0.6053
Epoch [46/200], Loss: 0.5986
Epoch [47/200], Loss: 0.6425
Epoch [48/200], Loss: 0.6754
Epoch [49/200], Loss: 0.7833
Epoch [50/200], Loss: 0.5100
Epoch [51/200], Loss: 0.4400
Epoch [52/200], Loss: 0.5800
Epoch [53/200], Loss: 0.7236
Epoch [54/200], Loss: 0.5464
Epoch [55/200], Loss: 0.7454
Epoch [56/200], Loss: 0.4591
Epoch [57/200], Loss: 0.6155
Epoch [58/200], Loss: 0.5594
Epoch [59/200], Loss: 0.5083
Epoch [60/200], Loss: 0.4967
Epoch [61/200], Loss: 0.4181
Epoch [62/200], Loss: 0.4903
Epoch [63/200], Loss: 0.3934
Epoch [64/200], Loss: 0.4546
Epoch [65/200], Loss: 0.3989
Epoch [66/200], Loss: 0.5297
Epoch [67/200], Loss: 0.4521
Epoch [68/200], Loss: 0.4839
Epoch [69/200], Loss: 0.6768
Epoch [70/200], Loss: 0.5294
Epoch [71/200], Loss: 0.4728
Epoch [72/200], Loss: 0.4577
Epoch [73/200], Loss: 0.4861
Epoch [74/200], Loss: 0.5381
Epoch [75/200], Loss: 0.5071
Epoch [76/200], Loss: 0.5488
Epoch [77/200], Loss: 0.4254
Epoch [78/200], Loss: 0.5197
Epoch [79/200], Loss: 0.5791
Epoch [80/200], Loss: 0.4702
Epoch [81/200], Loss: 0.4794
Epoch [82/200], Loss: 0.5258
Epoch [83/200], Loss: 0.4646
Epoch [84/200], Loss: 0.5217
Epoch [85/200], Loss: 0.4144
Epoch [86/200], Loss: 0.5532
Epoch [87/200], Loss: 0.5992
Epoch [88/200], Loss: 0.3958
Epoch [89/200], Loss: 0.6437
Epoch [90/200], Loss: 0.6095
Epoch [91/200], Loss: 0.7811
Epoch [92/200], Loss: 0.6039
Epoch [93/200], Loss: 0.4265
Epoch [94/200], Loss: 0.4262
Epoch [95/200], Loss: 0.5485
Epoch [96/200], Loss: 0.5329
Epoch [97/200], Loss: 0.5217
Epoch [98/200], Loss: 0.4942
Epoch [99/200], Loss: 0.5321
Epoch [100/200], Loss: 0.4227
Epoch [101/200], Loss: 0.5605
Epoch [102/200], Loss: 0.5494
Epoch [103/200], Loss: 0.4357
Epoch [104/200], Loss: 0.4189
Epoch [105/200], Loss: 0.4455
Epoch [106/200], Loss: 0.4857
Epoch [107/200], Loss: 0.4223
Epoch [108/200], Loss: 0.3919
Epoch [109/200], Loss: 0.5477
Epoch [110/200], Loss: 0.5150
Epoch [111/200], Loss: 0.3928
Epoch [112/200], Loss: 0.5727
Epoch [113/200], Loss: 0.4233
Epoch [114/200], Loss: 0.4912
Epoch [115/200], Loss: 0.5225
Epoch [116/200], Loss: 0.7488
Epoch [117/200], Loss: 0.4968
Epoch [118/200], Loss: 0.5543
Epoch [119/200], Loss: 0.5640
Epoch [120/200], Loss: 0.4800
Epoch [121/200], Loss: 0.5153
Epoch [122/200], Loss: 0.4879
Epoch [123/200], Loss: 0.6584
Epoch [124/200], Loss: 0.4898
Epoch [125/200], Loss: 0.5217
Epoch [126/200], Loss: 0.5672
Epoch [127/200], Loss: 0.4686
Epoch [128/200], Loss: 0.5661
Epoch [129/200], Loss: 0.4112
Epoch [130/200], Loss: 0.4503
Epoch [131/200], Loss: 0.4596
Epoch [132/200], Loss: 0.7574
Epoch [133/200], Loss: 0.6849
Epoch [134/200], Loss: 0.5490
Epoch [135/200], Loss: 0.4368
Epoch [136/200], Loss: 0.5017
Epoch [137/200], Loss: 0.7493
Epoch [138/200], Loss: 0.4297
Epoch [139/200], Loss: 0.5864
Epoch [140/200], Loss: 0.5867
Epoch [141/200], Loss: 0.6044
Epoch [142/200], Loss: 0.3962
Epoch [143/200], Loss: 0.6390
Epoch [144/200], Loss: 0.4549
Epoch [145/200], Loss: 0.3761
Epoch [146/200], Loss: 0.7408
Epoch [147/200], Loss: 0.5504
Epoch [148/200], Loss: 0.5031
Epoch [149/200], Loss: 0.5168
Epoch [150/200], Loss: 0.5928
Epoch [151/200], Loss: 0.4730
Epoch [152/200], Loss: 0.9359
Epoch [153/200], Loss: 0.5725
Epoch [154/200], Loss: 0.5288
Epoch [155/200], Loss: 0.8810
Epoch [156/200], Loss: 0.4265
Epoch [157/200], Loss: 0.6874
Epoch [158/200], Loss: 0.7146
Epoch [159/200], Loss: 0.7593
Epoch [160/200], Loss: 0.7084
Epoch [161/200], Loss: 0.5161
Epoch [162/200], Loss: 0.4035
Epoch [163/200], Loss: 0.4197
Epoch [164/200], Loss: 0.6768
Epoch [165/200], Loss: 0.5836
Epoch [166/200], Loss: 0.8528
Epoch [167/200], Loss: 0.5660
Epoch [168/200], Loss: 0.6709
Epoch [169/200], Loss: 0.4743
Epoch [170/200], Loss: 0.7732
Epoch [171/200], Loss: 0.6034
Epoch [172/200], Loss: 0.4200
Epoch [173/200], Loss: 0.5574
Epoch [174/200], Loss: 0.5068
Epoch [175/200], Loss: 0.8263
Epoch [176/200], Loss: 0.5844
Epoch [177/200], Loss: 0.5192
Epoch [178/200], Loss: 0.5176
Epoch [179/200], Loss: 0.4696
Epoch [180/200], Loss: 0.5911
Epoch [181/200], Loss: 0.5522
Epoch [182/200], Loss: 0.5825
Epoch [183/200], Loss: 0.4604
Epoch [184/200], Loss: 0.4647
Epoch [185/200], Loss: 0.7465
Epoch [186/200], Loss: 0.4415
Epoch [187/200], Loss: 0.5637
Epoch [188/200], Loss: 0.7054
Epoch [189/200], Loss: 0.4868
Epoch [190/200], Loss: 0.4771
Epoch [191/200], Loss: 0.4213
Epoch [192/200], Loss: 0.5650
Epoch [193/200], Loss: 0.5813
Epoch [194/200], Loss: 0.5344
Epoch [195/200], Loss: 0.7849
Epoch [196/200], Loss: 0.5394
Epoch [197/200], Loss: 0.5555
Epoch [198/200], Loss: 0.4097
Epoch [199/200], Loss: 0.6340
Epoch [200/200], Loss: 0.4478
Train class_to_idx: {'bus_stop_gym': 0, 'bus_stop_xiang_feng': 1, 'ntou_donut': 2, 'ntou_freedom_ship': 3}
Class bus_stop_gym has 5 samples
Class bus_stop_xiang_feng has 5 samples
Class ntou_donut has 6 samples
Class ntou_freedom_ship has 6 samples
Support set size: 12 samples
Query set size: 10 samples
Query 0: True = bus_stop_gym, Predicted = bus_stop_gym
Query 1: True = bus_stop_gym, Predicted = bus_stop_gym
Query 2: True = bus_stop_xiang_feng, Predicted = bus_stop_xiang_feng
Query 3: True = bus_stop_xiang_feng, Predicted = bus_stop_xiang_feng
Query 4: True = ntou_donut, Predicted = ntou_donut
Query 5: True = ntou_donut, Predicted = ntou_donut
Query 6: True = ntou_donut, Predicted = ntou_donut
Query 7: True = ntou_freedom_ship, Predicted = ntou_freedom_ship
Query 8: True = ntou_freedom_ship, Predicted = bus_stop_xiang_feng
Query 9: True = ntou_freedom_ship, Predicted = ntou_freedom_ship
Few-shot prototype classification accuracy: 0.90
Test class_to_idx: {'bus_stop_gym': 0, 'bus_stop_xiang_feng': 1, 'ntou_donut': 2, 'ntou_freedom_ship': 3}
GT: bus_stop_gym, Pred: bus_stop_gym
GT: bus_stop_xiang_feng, Pred: bus_stop_xiang_feng
GT: ntou_donut, Pred: ntou_donut
GT: ntou_freedom_ship, Pred: ntou_freedom_ship
Test accuracy: 1.00

[AutoEval] Running experiments for few_shot_k = 1 to 5

[AutoEval] --- Testing few_shot_k = 1 ---
→ Train acc = 0.83, Test acc = 0.75

[AutoEval] --- Testing few_shot_k = 2 ---
→ Train acc = 0.86, Test acc = 1.00

[AutoEval] --- Testing few_shot_k = 3 ---
→ Train acc = 0.90, Test acc = 1.00

[AutoEval] --- Testing few_shot_k = 4 ---
→ Train acc = 1.00, Test acc = 0.75

[AutoEval] --- Testing few_shot_k = 5 ---
→ Train acc = 1.00, Test acc = 0.75