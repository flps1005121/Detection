Total training samples: 22
Epoch [1/200], Loss: 1.2425
Epoch [2/200], Loss: 0.8292
Epoch [3/200], Loss: 0.8119
Epoch [4/200], Loss: 0.8894
Epoch [5/200], Loss: 0.6667
Epoch [6/200], Loss: 0.6715
Epoch [7/200], Loss: 0.7274
Epoch [8/200], Loss: 0.6801
Epoch [9/200], Loss: 0.6774
Epoch [10/200], Loss: 0.4914
Epoch [11/200], Loss: 0.5014
Epoch [12/200], Loss: 0.4171
Epoch [13/200], Loss: 0.5936
Epoch [14/200], Loss: 0.6165
Epoch [15/200], Loss: 0.5278
Epoch [16/200], Loss: 0.7384
Epoch [17/200], Loss: 0.4841
Epoch [18/200], Loss: 0.6224
Epoch [19/200], Loss: 0.4909
Epoch [20/200], Loss: 0.4742
Epoch [21/200], Loss: 0.4621
Epoch [22/200], Loss: 0.4841
Epoch [23/200], Loss: 0.4431
Epoch [24/200], Loss: 0.5896
Epoch [25/200], Loss: 0.5849
Epoch [26/200], Loss: 0.5275
Epoch [27/200], Loss: 0.5757
Epoch [28/200], Loss: 0.5139
Epoch [29/200], Loss: 0.5860
Epoch [30/200], Loss: 0.5201
Epoch [31/200], Loss: 0.4738
Epoch [32/200], Loss: 0.4376
Epoch [33/200], Loss: 0.4482
Epoch [34/200], Loss: 0.4933
Epoch [35/200], Loss: 0.4407
Epoch [36/200], Loss: 0.4253
Epoch [37/200], Loss: 0.4681
Epoch [38/200], Loss: 0.5078
Epoch [39/200], Loss: 0.5112
Epoch [40/200], Loss: 0.4496
Epoch [41/200], Loss: 0.3778
Epoch [42/200], Loss: 0.5333
Epoch [43/200], Loss: 0.5876
Epoch [44/200], Loss: 0.3763
Epoch [45/200], Loss: 0.4910
Epoch [46/200], Loss: 0.3765
Epoch [47/200], Loss: 0.3625
Epoch [48/200], Loss: 0.4942
Epoch [49/200], Loss: 0.4683
Epoch [50/200], Loss: 0.4872
Epoch [51/200], Loss: 0.4631
Epoch [52/200], Loss: 0.4410
Epoch [53/200], Loss: 0.5552
Epoch [54/200], Loss: 0.3970
Epoch [55/200], Loss: 0.4127
Epoch [56/200], Loss: 0.4424
Epoch [57/200], Loss: 0.4680
Epoch [58/200], Loss: 0.4937
Epoch [59/200], Loss: 0.4929
Epoch [60/200], Loss: 0.4530
Epoch [61/200], Loss: 0.4571
Epoch [62/200], Loss: 0.4617
Epoch [63/200], Loss: 0.5197
Epoch [64/200], Loss: 0.5545
Epoch [65/200], Loss: 0.5055
Epoch [66/200], Loss: 0.4278
Epoch [67/200], Loss: 0.7232
Epoch [68/200], Loss: 0.4474
Epoch [69/200], Loss: 0.5725
Epoch [70/200], Loss: 0.5423
Epoch [71/200], Loss: 0.4813
Epoch [72/200], Loss: 0.4143
Epoch [73/200], Loss: 0.4900
Epoch [74/200], Loss: 0.4926
Epoch [75/200], Loss: 0.6525
Epoch [76/200], Loss: 0.7694
Epoch [77/200], Loss: 0.5048
Epoch [78/200], Loss: 0.5050
Epoch [79/200], Loss: 0.5424
Epoch [80/200], Loss: 0.6217
Epoch [81/200], Loss: 0.4169
Epoch [82/200], Loss: 0.5721
Epoch [83/200], Loss: 0.4275
Epoch [84/200], Loss: 0.4503
Epoch [85/200], Loss: 0.5565
Epoch [86/200], Loss: 0.5023
Epoch [87/200], Loss: 0.4113
Epoch [88/200], Loss: 0.3991
Epoch [89/200], Loss: 0.4598
Epoch [90/200], Loss: 0.5034
Epoch [91/200], Loss: 0.6160
Epoch [92/200], Loss: 0.5348
Epoch [93/200], Loss: 0.4385
Epoch [94/200], Loss: 0.4390
Epoch [95/200], Loss: 0.5710
Epoch [96/200], Loss: 0.7003
Epoch [97/200], Loss: 0.4206
Epoch [98/200], Loss: 0.4634
Epoch [99/200], Loss: 0.3874
Epoch [100/200], Loss: 0.5309
Epoch [101/200], Loss: 0.4164
Epoch [102/200], Loss: 0.5631
Epoch [103/200], Loss: 0.5593
Epoch [104/200], Loss: 0.4755
Epoch [105/200], Loss: 0.3404
Epoch [106/200], Loss: 0.4237
Epoch [107/200], Loss: 0.4042
Epoch [108/200], Loss: 0.3941
Epoch [109/200], Loss: 0.4690
Epoch [110/200], Loss: 0.8427
Epoch [111/200], Loss: 0.4004
Epoch [112/200], Loss: 0.4770
Epoch [113/200], Loss: 0.8434
Epoch [114/200], Loss: 0.5078
Epoch [115/200], Loss: 0.3926
Epoch [116/200], Loss: 0.5783
Epoch [117/200], Loss: 0.4734
Epoch [118/200], Loss: 0.4219
Epoch [119/200], Loss: 0.4070
Epoch [120/200], Loss: 0.3829
Epoch [121/200], Loss: 0.3587
Epoch [122/200], Loss: 0.3258
Epoch [123/200], Loss: 0.4037
Epoch [124/200], Loss: 0.4332
Epoch [125/200], Loss: 0.3750
Epoch [126/200], Loss: 0.4528
Epoch [127/200], Loss: 0.4412
Epoch [128/200], Loss: 0.5546
Epoch [129/200], Loss: 0.3658
Epoch [130/200], Loss: 0.4537
Epoch [131/200], Loss: 0.4264
Epoch [132/200], Loss: 0.5557
Epoch [133/200], Loss: 0.4063
Epoch [134/200], Loss: 0.5279
Epoch [135/200], Loss: 0.4632
Epoch [136/200], Loss: 0.3891
Epoch [137/200], Loss: 0.4309
Epoch [138/200], Loss: 0.3716
Epoch [139/200], Loss: 0.4367
Epoch [140/200], Loss: 0.6591
Epoch [141/200], Loss: 0.3565
Epoch [142/200], Loss: 0.4726
Epoch [143/200], Loss: 0.4424
Epoch [144/200], Loss: 0.5090
Epoch [145/200], Loss: 0.5538
Epoch [146/200], Loss: 0.3987
Epoch [147/200], Loss: 0.3689
Epoch [148/200], Loss: 0.4085
Epoch [149/200], Loss: 0.5236
Epoch [150/200], Loss: 0.4429
Epoch [151/200], Loss: 0.6079
Epoch [152/200], Loss: 0.4411
Epoch [153/200], Loss: 0.3887
Epoch [154/200], Loss: 0.5356
Epoch [155/200], Loss: 0.3970
Epoch [156/200], Loss: 0.4312
Epoch [157/200], Loss: 0.3735
Epoch [158/200], Loss: 0.3697
Epoch [159/200], Loss: 0.3994
Epoch [160/200], Loss: 0.3357
Epoch [161/200], Loss: 0.3480
Epoch [162/200], Loss: 0.4111
Epoch [163/200], Loss: 0.4963
Epoch [164/200], Loss: 0.3952
Epoch [165/200], Loss: 0.3747
Epoch [166/200], Loss: 0.3495
Epoch [167/200], Loss: 0.4482
Epoch [168/200], Loss: 0.3656
Epoch [169/200], Loss: 0.3857
Epoch [170/200], Loss: 0.3687
Epoch [171/200], Loss: 0.4632
Epoch [172/200], Loss: 0.3530
Epoch [173/200], Loss: 0.4072
Epoch [174/200], Loss: 0.6943
Epoch [175/200], Loss: 0.4422
Epoch [176/200], Loss: 0.3773
Epoch [177/200], Loss: 0.3980
Epoch [178/200], Loss: 0.4497
Epoch [179/200], Loss: 0.3424
Epoch [180/200], Loss: 0.6024
Epoch [181/200], Loss: 0.3712
Epoch [182/200], Loss: 0.5114
Epoch [183/200], Loss: 0.3677
Epoch [184/200], Loss: 0.4013
Epoch [185/200], Loss: 0.4062
Epoch [186/200], Loss: 0.3908
Epoch [187/200], Loss: 0.3706
Epoch [188/200], Loss: 0.3866
Epoch [189/200], Loss: 0.3657
Epoch [190/200], Loss: 0.3560
Epoch [191/200], Loss: 0.3770
Epoch [192/200], Loss: 0.4176
Epoch [193/200], Loss: 0.3562
Epoch [194/200], Loss: 0.3707
Epoch [195/200], Loss: 0.4307
Epoch [196/200], Loss: 0.3370
Epoch [197/200], Loss: 0.3601
Epoch [198/200], Loss: 0.3569
Epoch [199/200], Loss: 0.5013
Epoch [200/200], Loss: 0.3829
Train class_to_idx: {'bus_stop_gym': 0, 'bus_stop_xiang_feng': 1, 'ntou_donut': 2, 'ntou_freedom_ship': 3}
Support set size: 12 samples
Query set size: 10 samples
Query 0: True = bus_stop_gym, Predicted = bus_stop_gym
Query 1: True = bus_stop_gym, Predicted = bus_stop_gym
Query 2: True = bus_stop_xiang_feng, Predicted = bus_stop_xiang_feng
Query 3: True = bus_stop_xiang_feng, Predicted = bus_stop_xiang_feng
Query 4: True = ntou_donut, Predicted = ntou_donut
Query 5: True = ntou_donut, Predicted = ntou_donut
Query 6: True = ntou_donut, Predicted = ntou_donut
Query 7: True = ntou_freedom_ship, Predicted = ntou_freedom_ship
Query 8: True = ntou_freedom_ship, Predicted = ntou_freedom_ship
Query 9: True = ntou_freedom_ship, Predicted = ntou_freedom_ship
Few-shot prototype classification accuracy: 1.00
GT: bus_stop_gym, Pred: bus_stop_gym
GT: bus_stop_xiang_feng, Pred: bus_stop_xiang_feng
GT: ntou_donut, Pred: ntou_donut
GT: ntou_freedom_ship, Pred: ntou_freedom_ship
Test accuracy: 1.00

[AutoEval] Running experiments for few_shot_k = 1 to 5

[AutoEval] --- Testing few_shot_k = 1 ---
→ Train acc = 0.83, Test acc = 1.00

[AutoEval] --- Testing few_shot_k = 2 ---
→ Train acc = 0.71, Test acc = 0.75

[AutoEval] --- Testing few_shot_k = 3 ---
→ Train acc = 0.80, Test acc = 1.00

[AutoEval] --- Testing few_shot_k = 4 ---
→ Train acc = 0.67, Test acc = 1.00

[AutoEval] --- Testing few_shot_k = 5 ---
→ Train acc = 1.00, Test acc = 1.00
