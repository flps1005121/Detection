Total training samples: 22
Epoch [1/200], Loss: 1.2292
Epoch [2/200], Loss: 0.9243
Epoch [3/200], Loss: 0.6473
Epoch [4/200], Loss: 0.7085
Epoch [5/200], Loss: 0.7918
Epoch [6/200], Loss: 0.9219
Epoch [7/200], Loss: 0.7415
Epoch [8/200], Loss: 0.8801
Epoch [9/200], Loss: 0.6798
Epoch [10/200], Loss: 0.9315
Epoch [11/200], Loss: 0.8090
Epoch [12/200], Loss: 0.7297
Epoch [13/200], Loss: 0.8347
Epoch [14/200], Loss: 0.5659
Epoch [15/200], Loss: 0.5471
Epoch [16/200], Loss: 0.5179
Epoch [17/200], Loss: 0.5841
Epoch [18/200], Loss: 0.8830
Epoch [19/200], Loss: 0.5866
Epoch [20/200], Loss: 0.6298
Epoch [21/200], Loss: 0.6547
Epoch [22/200], Loss: 0.6668
Epoch [23/200], Loss: 0.7307
Epoch [24/200], Loss: 0.7005
Epoch [25/200], Loss: 0.5799
Epoch [26/200], Loss: 0.5285
Epoch [27/200], Loss: 0.7929
Epoch [28/200], Loss: 0.5294
Epoch [29/200], Loss: 0.5655
Epoch [30/200], Loss: 0.6033
Epoch [31/200], Loss: 0.5932
Epoch [32/200], Loss: 0.8829
Epoch [33/200], Loss: 0.4565
Epoch [34/200], Loss: 0.5990
Epoch [35/200], Loss: 0.5107
Epoch [36/200], Loss: 0.6255
Epoch [37/200], Loss: 0.6072
Epoch [38/200], Loss: 0.5183
Epoch [39/200], Loss: 0.4169
Epoch [40/200], Loss: 0.4877
Epoch [41/200], Loss: 0.4552
Epoch [42/200], Loss: 0.6013
Epoch [43/200], Loss: 0.5795
Epoch [44/200], Loss: 0.5643
Epoch [45/200], Loss: 0.5504
Epoch [46/200], Loss: 0.4939
Epoch [47/200], Loss: 0.5038
Epoch [48/200], Loss: 0.4380
Epoch [49/200], Loss: 0.4668
Epoch [50/200], Loss: 0.5046
Epoch [51/200], Loss: 0.4249
Epoch [52/200], Loss: 0.7080
Epoch [53/200], Loss: 0.4694
Epoch [54/200], Loss: 0.6736
Epoch [55/200], Loss: 0.7112
Epoch [56/200], Loss: 0.5568
Epoch [57/200], Loss: 0.4604
Epoch [58/200], Loss: 0.5883
Epoch [59/200], Loss: 0.7334
Epoch [60/200], Loss: 0.4529
Epoch [61/200], Loss: 0.6484
Epoch [62/200], Loss: 0.5177
Epoch [63/200], Loss: 0.3722
Epoch [64/200], Loss: 0.6283
Epoch [65/200], Loss: 0.5716
Epoch [66/200], Loss: 0.4529
Epoch [67/200], Loss: 0.4288
Epoch [68/200], Loss: 0.7112
Epoch [69/200], Loss: 0.4916
Epoch [70/200], Loss: 0.5150
Epoch [71/200], Loss: 0.3974
Epoch [72/200], Loss: 0.4789
Epoch [73/200], Loss: 0.5840
Epoch [74/200], Loss: 0.5807
Epoch [75/200], Loss: 0.5728
Epoch [76/200], Loss: 0.5907
Epoch [77/200], Loss: 0.5547
Epoch [78/200], Loss: 0.3625
Epoch [79/200], Loss: 0.4303
Epoch [80/200], Loss: 0.3651
Epoch [81/200], Loss: 0.4747
Epoch [82/200], Loss: 0.4018
Epoch [83/200], Loss: 0.4256
Epoch [84/200], Loss: 0.5808
Epoch [85/200], Loss: 0.3739
Epoch [86/200], Loss: 0.3942
Epoch [87/200], Loss: 0.4698
Epoch [88/200], Loss: 0.3946
Epoch [89/200], Loss: 0.4646
Epoch [90/200], Loss: 0.3887
Epoch [91/200], Loss: 0.9094
Epoch [92/200], Loss: 0.5469
Epoch [93/200], Loss: 0.5112
Epoch [94/200], Loss: 0.4553
Epoch [95/200], Loss: 0.4530
Epoch [96/200], Loss: 0.5122
Epoch [97/200], Loss: 0.7495
Epoch [98/200], Loss: 0.4411
Epoch [99/200], Loss: 0.7546
Epoch [100/200], Loss: 0.4552
Epoch [101/200], Loss: 0.5405
Epoch [102/200], Loss: 0.4681
Epoch [103/200], Loss: 0.3780
Epoch [104/200], Loss: 0.5366
Epoch [105/200], Loss: 0.4398
Epoch [106/200], Loss: 0.4396
Epoch [107/200], Loss: 0.5124
Epoch [108/200], Loss: 0.4396
Epoch [109/200], Loss: 0.4098
Epoch [110/200], Loss: 0.4684
Epoch [111/200], Loss: 0.3902
Epoch [112/200], Loss: 0.4284
Epoch [113/200], Loss: 0.4152
Epoch [114/200], Loss: 0.4301
Epoch [115/200], Loss: 0.4116
Epoch [116/200], Loss: 0.3788
Epoch [117/200], Loss: 0.4135
Epoch [118/200], Loss: 0.3916
Epoch [119/200], Loss: 0.4085
Epoch [120/200], Loss: 0.3837
Epoch [121/200], Loss: 0.4731
Epoch [122/200], Loss: 0.3790
Epoch [123/200], Loss: 0.3994
Epoch [124/200], Loss: 0.3388
Epoch [125/200], Loss: 0.3747
Epoch [126/200], Loss: 0.3482
Epoch [127/200], Loss: 0.4830
Epoch [128/200], Loss: 0.4076
Epoch [129/200], Loss: 0.4774
Epoch [130/200], Loss: 0.5094
Epoch [131/200], Loss: 0.3882
Epoch [132/200], Loss: 0.4607
Epoch [133/200], Loss: 0.4533
Epoch [134/200], Loss: 0.4454
Epoch [135/200], Loss: 0.4225
Epoch [136/200], Loss: 0.4516
Epoch [137/200], Loss: 0.5230
Epoch [138/200], Loss: 0.4993
Epoch [139/200], Loss: 0.4404
Epoch [140/200], Loss: 0.3629
Epoch [141/200], Loss: 0.3817
Epoch [142/200], Loss: 0.3652
Epoch [143/200], Loss: 0.4411
Epoch [144/200], Loss: 0.4252
Epoch [145/200], Loss: 0.5078
Epoch [146/200], Loss: 0.4156
Epoch [147/200], Loss: 0.4789
Epoch [148/200], Loss: 0.5772
Epoch [149/200], Loss: 0.6782
Epoch [150/200], Loss: 0.4809
Epoch [151/200], Loss: 0.4805
Epoch [152/200], Loss: 0.5339
Epoch [153/200], Loss: 0.4625
Epoch [154/200], Loss: 0.5397
Epoch [155/200], Loss: 0.4551
Epoch [156/200], Loss: 0.3529
Epoch [157/200], Loss: 0.4660
Epoch [158/200], Loss: 0.4199
Epoch [159/200], Loss: 0.5588
Epoch [160/200], Loss: 0.4392
Epoch [161/200], Loss: 0.5716
Epoch [162/200], Loss: 0.3913
Epoch [163/200], Loss: 0.4613
Epoch [164/200], Loss: 0.4324
Epoch [165/200], Loss: 0.4056
Epoch [166/200], Loss: 0.4573
Epoch [167/200], Loss: 0.4756
Epoch [168/200], Loss: 0.4273
Epoch [169/200], Loss: 0.4387
Epoch [170/200], Loss: 0.3524
Epoch [171/200], Loss: 0.4132
Epoch [172/200], Loss: 0.3986
Epoch [173/200], Loss: 0.3860
Epoch [174/200], Loss: 0.5652
Epoch [175/200], Loss: 0.4230
Epoch [176/200], Loss: 0.5297
Epoch [177/200], Loss: 0.5098
Epoch [178/200], Loss: 0.5207
Epoch [179/200], Loss: 0.5065
Epoch [180/200], Loss: 0.4370
Epoch [181/200], Loss: 0.4094
Epoch [182/200], Loss: 0.4863
Epoch [183/200], Loss: 0.5167
Epoch [184/200], Loss: 0.3882
Epoch [185/200], Loss: 0.3512
Epoch [186/200], Loss: 0.3760
Epoch [187/200], Loss: 0.3367
Epoch [188/200], Loss: 0.5172
Epoch [189/200], Loss: 0.3527
Epoch [190/200], Loss: 0.4192
Epoch [191/200], Loss: 0.3948
Epoch [192/200], Loss: 0.3846
Epoch [193/200], Loss: 0.5063
Epoch [194/200], Loss: 0.4069
Epoch [195/200], Loss: 0.5971
Epoch [196/200], Loss: 0.3929
Epoch [197/200], Loss: 0.4087
Epoch [198/200], Loss: 0.4597
Epoch [199/200], Loss: 0.5025
Epoch [200/200], Loss: 0.5778
Train class_to_idx: {'bus_stop_gym': 0, 'bus_stop_xiang_feng': 1, 'ntou_donut': 2, 'ntou_freedom_ship': 3}
Support set size: 12 samples
Query set size: 10 samples
Query 0: True = bus_stop_gym, Predicted = bus_stop_gym
Query 1: True = bus_stop_gym, Predicted = bus_stop_xiang_feng
Query 2: True = bus_stop_xiang_feng, Predicted = bus_stop_xiang_feng
Query 3: True = bus_stop_xiang_feng, Predicted = bus_stop_xiang_feng
Query 4: True = ntou_donut, Predicted = ntou_donut
Query 5: True = ntou_donut, Predicted = ntou_donut
Query 6: True = ntou_donut, Predicted = ntou_donut
Query 7: True = ntou_freedom_ship, Predicted = ntou_freedom_ship
Query 8: True = ntou_freedom_ship, Predicted = ntou_freedom_ship
Query 9: True = ntou_freedom_ship, Predicted = ntou_freedom_ship
Few-shot prototype classification accuracy: 0.90
GT: bus_stop_gym, Pred: bus_stop_gym
GT: bus_stop_xiang_feng, Pred: bus_stop_xiang_feng
GT: ntou_donut, Pred: ntou_donut
GT: ntou_freedom_ship, Pred: ntou_freedom_ship
Test accuracy: 1.00

[AutoEval] Running experiments for few_shot_k = 1 to 5

[AutoEval] --- Testing few_shot_k = 1 ---
→ Train acc = 0.67, Test acc = 0.75

[AutoEval] --- Testing few_shot_k = 2 ---
→ Train acc = 0.93, Test acc = 1.00

[AutoEval] --- Testing few_shot_k = 3 ---
→ Train acc = 0.80, Test acc = 0.75

[AutoEval] --- Testing few_shot_k = 4 ---
→ Train acc = 0.83, Test acc = 1.00

[AutoEval] --- Testing few_shot_k = 5 ---
→ Train acc = 1.00, Test acc = 1.00
