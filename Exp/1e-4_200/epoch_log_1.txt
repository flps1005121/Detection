Total training samples: 22
Epoch [1/200], Loss: 1.4994
Epoch [2/200], Loss: 0.8795
Epoch [3/200], Loss: 0.8041
Epoch [4/200], Loss: 0.7966
Epoch [5/200], Loss: 0.5782
Epoch [6/200], Loss: 0.5815
Epoch [7/200], Loss: 0.6913
Epoch [8/200], Loss: 0.7485
Epoch [9/200], Loss: 0.5992
Epoch [10/200], Loss: 0.6171
Epoch [11/200], Loss: 0.5901
Epoch [12/200], Loss: 0.6553
Epoch [13/200], Loss: 0.7378
Epoch [14/200], Loss: 0.5181
Epoch [15/200], Loss: 0.6319
Epoch [16/200], Loss: 0.6538
Epoch [17/200], Loss: 0.5770
Epoch [18/200], Loss: 0.6019
Epoch [19/200], Loss: 0.5407
Epoch [20/200], Loss: 1.1705
Epoch [21/200], Loss: 0.4356
Epoch [22/200], Loss: 0.7076
Epoch [23/200], Loss: 0.5354
Epoch [24/200], Loss: 0.4542
Epoch [25/200], Loss: 0.5208
Epoch [26/200], Loss: 0.5496
Epoch [27/200], Loss: 0.5986
Epoch [28/200], Loss: 0.4292
Epoch [29/200], Loss: 0.7604
Epoch [30/200], Loss: 0.5821
Epoch [31/200], Loss: 0.4172
Epoch [32/200], Loss: 0.5128
Epoch [33/200], Loss: 0.5573
Epoch [34/200], Loss: 0.5218
Epoch [35/200], Loss: 0.6257
Epoch [36/200], Loss: 0.5044
Epoch [37/200], Loss: 0.4684
Epoch [38/200], Loss: 0.5221
Epoch [39/200], Loss: 0.4634
Epoch [40/200], Loss: 0.4809
Epoch [41/200], Loss: 0.5109
Epoch [42/200], Loss: 0.5091
Epoch [43/200], Loss: 0.4229
Epoch [44/200], Loss: 0.5862
Epoch [45/200], Loss: 0.4104
Epoch [46/200], Loss: 0.4809
Epoch [47/200], Loss: 0.4366
Epoch [48/200], Loss: 0.4188
Epoch [49/200], Loss: 0.4336
Epoch [50/200], Loss: 0.4284
Epoch [51/200], Loss: 0.3900
Epoch [52/200], Loss: 0.5101
Epoch [53/200], Loss: 0.4935
Epoch [54/200], Loss: 0.5019
Epoch [55/200], Loss: 0.4344
Epoch [56/200], Loss: 0.3846
Epoch [57/200], Loss: 0.5364
Epoch [58/200], Loss: 0.4277
Epoch [59/200], Loss: 0.4840
Epoch [60/200], Loss: 0.4514
Epoch [61/200], Loss: 0.4258
Epoch [62/200], Loss: 0.4268
Epoch [63/200], Loss: 0.3445
Epoch [64/200], Loss: 0.4466
Epoch [65/200], Loss: 0.4205
Epoch [66/200], Loss: 0.3770
Epoch [67/200], Loss: 0.4380
Epoch [68/200], Loss: 0.4609
Epoch [69/200], Loss: 0.4136
Epoch [70/200], Loss: 0.4377
Epoch [71/200], Loss: 0.4113
Epoch [72/200], Loss: 0.3844
Epoch [73/200], Loss: 0.4565
Epoch [74/200], Loss: 0.4411
Epoch [75/200], Loss: 0.4530
Epoch [76/200], Loss: 0.4202
Epoch [77/200], Loss: 0.5500
Epoch [78/200], Loss: 0.5294
Epoch [79/200], Loss: 0.4403
Epoch [80/200], Loss: 0.9690
Epoch [81/200], Loss: 0.5375
Epoch [82/200], Loss: 0.5395
Epoch [83/200], Loss: 0.4706
Epoch [84/200], Loss: 0.5457
Epoch [85/200], Loss: 0.4204
Epoch [86/200], Loss: 0.4699
Epoch [87/200], Loss: 0.4421
Epoch [88/200], Loss: 0.3819
Epoch [89/200], Loss: 0.6065
Epoch [90/200], Loss: 0.4806
Epoch [91/200], Loss: 0.4773
Epoch [92/200], Loss: 0.4998
Epoch [93/200], Loss: 0.4298
Epoch [94/200], Loss: 0.5089
Epoch [95/200], Loss: 0.4273
Epoch [96/200], Loss: 0.4035
Epoch [97/200], Loss: 0.4218
Epoch [98/200], Loss: 0.4267
Epoch [99/200], Loss: 0.3840
Epoch [100/200], Loss: 0.3999
Epoch [101/200], Loss: 0.4488
Epoch [102/200], Loss: 0.4456
Epoch [103/200], Loss: 0.3742
Epoch [104/200], Loss: 0.3395
Epoch [105/200], Loss: 0.4724
Epoch [106/200], Loss: 0.4720
Epoch [107/200], Loss: 0.3814
Epoch [108/200], Loss: 0.4083
Epoch [109/200], Loss: 0.3640
Epoch [110/200], Loss: 0.3708
Epoch [111/200], Loss: 0.4566
Epoch [112/200], Loss: 0.3484
Epoch [113/200], Loss: 0.3867
Epoch [114/200], Loss: 0.3795
Epoch [115/200], Loss: 0.3828
Epoch [116/200], Loss: 0.4109
Epoch [117/200], Loss: 0.3891
Epoch [118/200], Loss: 0.4199
Epoch [119/200], Loss: 0.4653
Epoch [120/200], Loss: 0.3566
Epoch [121/200], Loss: 0.4192
Epoch [122/200], Loss: 0.3943
Epoch [123/200], Loss: 0.3338
Epoch [124/200], Loss: 0.3502
Epoch [125/200], Loss: 0.4985
Epoch [126/200], Loss: 0.5025
Epoch [127/200], Loss: 0.4615
Epoch [128/200], Loss: 0.4854
Epoch [129/200], Loss: 0.5253
Epoch [130/200], Loss: 0.3582
Epoch [131/200], Loss: 0.4432
Epoch [132/200], Loss: 0.4649
Epoch [133/200], Loss: 0.4682
Epoch [134/200], Loss: 0.6156
Epoch [135/200], Loss: 0.3756
Epoch [136/200], Loss: 0.3697
Epoch [137/200], Loss: 0.3764
Epoch [138/200], Loss: 0.5009
Epoch [139/200], Loss: 0.4038
Epoch [140/200], Loss: 0.3735
Epoch [141/200], Loss: 0.5507
Epoch [142/200], Loss: 0.3826
Epoch [143/200], Loss: 0.5846
Epoch [144/200], Loss: 0.4539
Epoch [145/200], Loss: 0.4493
Epoch [146/200], Loss: 0.4935
Epoch [147/200], Loss: 0.4186
Epoch [148/200], Loss: 0.7440
Epoch [149/200], Loss: 0.5549
Epoch [150/200], Loss: 0.4854
Epoch [151/200], Loss: 0.5711
Epoch [152/200], Loss: 0.4224
Epoch [153/200], Loss: 0.5694
Epoch [154/200], Loss: 0.5206
Epoch [155/200], Loss: 0.4492
Epoch [156/200], Loss: 0.3785
Epoch [157/200], Loss: 0.4209
Epoch [158/200], Loss: 0.4563
Epoch [159/200], Loss: 0.4510
Epoch [160/200], Loss: 0.4767
Epoch [161/200], Loss: 0.3636
Epoch [162/200], Loss: 0.4696
Epoch [163/200], Loss: 0.4227
Epoch [164/200], Loss: 0.3973
Epoch [165/200], Loss: 0.4297
Epoch [166/200], Loss: 0.4669
Epoch [167/200], Loss: 0.4476
Epoch [168/200], Loss: 0.4812
Epoch [169/200], Loss: 0.4290
Epoch [170/200], Loss: 0.4352
Epoch [171/200], Loss: 0.4194
Epoch [172/200], Loss: 0.4140
Epoch [173/200], Loss: 0.3733
Epoch [174/200], Loss: 0.5710
Epoch [175/200], Loss: 0.3563
Epoch [176/200], Loss: 0.3937
Epoch [177/200], Loss: 0.5506
Epoch [178/200], Loss: 0.4142
Epoch [179/200], Loss: 0.5154
Epoch [180/200], Loss: 0.4589
Epoch [181/200], Loss: 0.5035
Epoch [182/200], Loss: 0.4198
Epoch [183/200], Loss: 0.3994
Epoch [184/200], Loss: 0.3966
Epoch [185/200], Loss: 0.3421
Epoch [186/200], Loss: 0.5768
Epoch [187/200], Loss: 0.4658
Epoch [188/200], Loss: 0.4184
Epoch [189/200], Loss: 0.3671
Epoch [190/200], Loss: 0.4883
Epoch [191/200], Loss: 0.3373
Epoch [192/200], Loss: 0.3474
Epoch [193/200], Loss: 0.3559
Epoch [194/200], Loss: 0.3480
Epoch [195/200], Loss: 0.3771
Epoch [196/200], Loss: 0.4714
Epoch [197/200], Loss: 0.4996
Epoch [198/200], Loss: 0.3852
Epoch [199/200], Loss: 0.4339
Epoch [200/200], Loss: 0.4671
Train class_to_idx: {'bus_stop_gym': 0, 'bus_stop_xiang_feng': 1, 'ntou_donut': 2, 'ntou_freedom_ship': 3}
Class bus_stop_gym has 5 samples
Class bus_stop_xiang_feng has 5 samples
Class ntou_donut has 6 samples
Class ntou_freedom_ship has 6 samples
Support set size: 12 samples
Query set size: 10 samples
Query 0: True = bus_stop_gym, Predicted = bus_stop_gym
Query 1: True = bus_stop_gym, Predicted = bus_stop_gym
Query 2: True = bus_stop_xiang_feng, Predicted = bus_stop_xiang_feng
Query 3: True = bus_stop_xiang_feng, Predicted = bus_stop_xiang_feng
Query 4: True = ntou_donut, Predicted = ntou_donut
Query 5: True = ntou_donut, Predicted = ntou_donut
Query 6: True = ntou_donut, Predicted = ntou_donut
Query 7: True = ntou_freedom_ship, Predicted = ntou_freedom_ship
Query 8: True = ntou_freedom_ship, Predicted = ntou_freedom_ship
Query 9: True = ntou_freedom_ship, Predicted = ntou_freedom_ship
Few-shot prototype classification accuracy: 1.00
Test class_to_idx: {'bus_stop_gym': 0, 'bus_stop_xiang_feng': 1, 'ntou_donut': 2, 'ntou_freedom_ship': 3}
GT: bus_stop_gym, Pred: bus_stop_gym
GT: bus_stop_xiang_feng, Pred: ntou_freedom_ship
GT: ntou_donut, Pred: ntou_donut
GT: ntou_freedom_ship, Pred: ntou_freedom_ship
Test accuracy: 0.75

[AutoEval] Running experiments for few_shot_k = 1 to 5

[AutoEval] --- Testing few_shot_k = 1 ---
→ Train acc = 0.72, Test acc = 0.50

[AutoEval] --- Testing few_shot_k = 2 ---
→ Train acc = 0.79, Test acc = 0.75

[AutoEval] --- Testing few_shot_k = 3 ---
→ Train acc = 1.00, Test acc = 0.75

[AutoEval] --- Testing few_shot_k = 4 ---
→ Train acc = 0.83, Test acc = 0.75

[AutoEval] --- Testing few_shot_k = 5 ---
→ Train acc = 1.00, Test acc = 0.75