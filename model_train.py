import torch
import torch.nn as nn
import torch.nn.functional as F
import torch.optim as optim
import torchvision.transforms as transforms
from torchvision import transforms, models
from torchvision.datasets import ImageFolder
from torch.utils.data import DataLoader, Dataset
from PIL import Image
import os
import numpy as np
import matplotlib.pyplot as plt
import json
from tqdm import tqdm

# è¶…åƒæ•¸è¨­å®š
DATA_DIR = "dataset/train"
BATCH_SIZE = 256
NUM_WORKERS = 4
LEARNING_RATE = 0.001
TEMPERATURE = 0.07
EPOCHS = 10
LOSSES_FILE = "output/training_losses.json"
MODEL_SAVE_PATH = "output/simclr_mobilenetv3.pth"
OUTPUT_DIR = "output/"
FEATURE_DIM = 128

# è¨­ç½®è¨­å‚™
device = torch.device("mps" if torch.backends.mps.is_available() else "cuda" if torch.cuda.is_available() else "cpu")

class CBAM(nn.Module):
    def __init__(self, channels, reduction=16, kernel_size=7):
        super().__init__()
        # Channel Attention
        self.avg_pool = nn.AdaptiveAvgPool2d(1)
        self.max_pool = nn.AdaptiveMaxPool2d(1)
        self.fc = nn.Sequential(
            nn.Conv2d(channels, channels // reduction, 1, bias=False),
            nn.ReLU(),
            nn.Conv2d(channels // reduction, channels, 1, bias=False)
        )
        self.sigmoid_channel = nn.Sigmoid()

        # Spatial Attention
        self.conv_spatial = nn.Conv2d(2, 1, kernel_size, padding=kernel_size // 2, bias=False)
        self.sigmoid_spatial = nn.Sigmoid()

        # For visualization
        self.last_channel_attention = None
        self.last_spatial_attention = None

    def forward(self, x):
        # --- Channel Attention ---
        avg_out = self.fc(self.avg_pool(x))
        max_out = self.fc(self.max_pool(x))
        channel_attention = self.sigmoid_channel(avg_out + max_out)

        # ğŸ”¸ å„²å­˜ channel attentionï¼ˆå¯ç”¨æ–¼è¦–è¦ºåŒ–ï¼‰
        self.last_channel_attention = channel_attention.detach()

        x = x * channel_attention  # Broadcasting: [B, C, H, W] * [B, C, 1, 1]

        # --- Spatial Attention ---
        avg_out = torch.mean(x, dim=1, keepdim=True)       # [B, 1, H, W]
        max_out, _ = torch.max(x, dim=1, keepdim=True)      # [B, 1, H, W]
        x_cat = torch.cat([avg_out, max_out], dim=1)        # [B, 2, H, W]
        spatial_attention = self.sigmoid_spatial(self.conv_spatial(x_cat))  # [B, 1, H, W]

        # ğŸ”¸ å„²å­˜ spatial attentionï¼ˆå¯ç”¨æ–¼è¦–è¦ºåŒ–ï¼‰
        self.last_spatial_attention = spatial_attention.detach()

        x = x * spatial_attention

        return x



# è³‡æ–™é›†å®šç¾©
class SimCLRDataset(Dataset):
    def __init__(self, root_dir, transform):
        self.dataset = ImageFolder(root=root_dir, transform=None)
        self.transform = transform

    def __len__(self):
        return len(self.dataset)

    def __getitem__(self, index):
        image, label = self.dataset[index]
        x1 = self.transform(image)
        x2 = self.transform(image)
        return x1, x2, label

# å®šç¾©æ•¸æ“šå¢å¼·
contrast_transforms = transforms.Compose([
    transforms.RandomResizedCrop(224),
    transforms.RandomHorizontalFlip(),
    transforms.ColorJitter(0.5, 0.5, 0.5, 0.1),
    transforms.RandomGrayscale(p=0.2),
    transforms.ToTensor(),
    transforms.Normalize((0.5, 0.5, 0.5), (0.5, 0.5, 0.5))
])

# è‡ªç›£ç£å­¸ç¿’æ¨¡å‹
class SimCLRNet(nn.Module):
    def __init__(self, feature_dim=FEATURE_DIM):
        super().__init__()
        # ä½¿ç”¨ MobileNetV3 Small ä½œç‚ºåŸºç¤æ¨¡å‹
        self.backbone = models.mobilenet_v3_small(weights=models.MobileNet_V3_Small_Weights.DEFAULT)
        self.backbone.classifier = nn.Identity()

        self.cbam = CBAM(channels=576)  # CBAM æ¨¡çµ„

        self.projector = nn.Sequential(
            nn.Linear(576, 512),             # ç¬¬ä¸€å±¤å…¨é€£æ¥å±¤
            nn.BatchNorm1d(512),             # æ‰¹æ¬¡æ­£è¦åŒ–ï¼Œç©©å®šè¨“ç·´
            nn.ReLU(),                       # æ¿€æ´»å‡½æ•¸
            nn.Dropout(0.2),                 # Dropout é˜²æ­¢éæ“¬åˆ
            nn.Linear(512, 512),             # ç¬¬äºŒå±¤å…¨é€£æ¥å±¤
            nn.BatchNorm1d(512),             # æ‰¹æ¬¡æ­£è¦åŒ–
            nn.ReLU(),                       # æ¿€æ´»å‡½æ•¸
            nn.Dropout(0.2),                 # Dropout
            nn.Linear(512, feature_dim)      # æœ€çµ‚æ˜ å°„åˆ°æŒ‡å®šç‰¹å¾µç¶­åº¦
        )


    def forward(self, x):
        h = self.backbone.features(x)
        h = self.cbam(h)  # CBAM æ¨¡çµ„
        h = F.adaptive_avg_pool2d(h, (1, 1))
        h = h.view(h.size(0), -1)
        # æ·»åŠ ç‰¹å¾µç¶­åº¦èª¿è©¦è³‡è¨Š (ç¬¬ä¸€æ¬¡åŸ·è¡Œæ™‚å¯ä»¥å–æ¶ˆé€™è¡Œçš„è¨»è§£ä¾†æª¢æŸ¥ç¶­åº¦)
        # print(f"Feature shape: {h.shape}")
        z = self.projector(h)
        return F.normalize(z, dim=1)


# å°æ¯”å­¸ç¿’æå¤±å‡½æ•¸
class NTXentLoss(nn.Module):
    def __init__(self, temperature=0.5):
        super().__init__()
        self.temperature = temperature

    def forward(self, z1, z2):
        z = torch.cat([z1, z2], dim=0)
        N = z1.size(0)
        sim = F.cosine_similarity(z.unsqueeze(1), z.unsqueeze(0), dim=2)
        sim = sim / self.temperature
        mask = ~torch.eye(2 * N, dtype=bool).to(device)
        sim = sim.masked_fill(~mask, -9e15)
        labels = torch.cat([torch.arange(N) + N, torch.arange(N)]).to(device)
        return F.cross_entropy(sim, labels)

# è‡ªç›£ç£è¨“ç·´å‡½æ•¸
def train_self_supervised(model, data_loader, optimizer, criterion, device, epochs, save_path=None):
    losses = []
    best_loss = float("inf")
    patience = 10
    counter = 0

    for epoch in range(epochs):
        model.train()
        running_loss = 0.0
        for x1, x2, _ in tqdm(data_loader, desc=f"Epoch {epoch+1}/{epochs}"):
            # ç²å–å…©ç¨®å¢å¼·ç‰ˆæœ¬çš„åœ–åƒ
            x1, x2 = x1.to(device), x2.to(device)
            z1, z2 = model(x1), model(x2)
            loss = criterion(z1, z2)
            optimizer.zero_grad()
            # è¨ˆç®—æå¤±ä¸¦åå‘å‚³æ’­
            loss.backward()
            optimizer.step()
            running_loss += loss.item()
        # è¨˜éŒ„æ¯å€‹ epoch çš„æå¤±
        epoch_loss = running_loss / len(data_loader)
        losses.append(epoch_loss)
        print(f'Epoch {epoch+1}/{epochs}, Loss: {epoch_loss:.4f}')

        # æ—©åœæª¢æŸ¥
        if epoch_loss < best_loss:
            best_loss = epoch_loss
            counter = 0
            # å¯é¸ï¼šå„²å­˜æœ€ä½³æ¨¡å‹
            torch.save(model.state_dict(), os.path.join(OUTPUT_DIR, "best_model.pth"))
            print(f"å„²å­˜æœ€ä½³æ¨¡å‹è‡³: {os.path.join(OUTPUT_DIR, 'best_model.pth')}")
        else:
            counter += 1
            if counter >= patience:
                print(f"Early stoppingï¼åœ¨ç¬¬ {epoch+1} epoch æ¨¡å‹ä¸å†é€²æ­¥")
                break

        # æ¯å€‹ epoch å„²å­˜ä¸€æ¬¡æå¤±è¨˜éŒ„
        if save_path:
            with open(save_path, 'w') as f:
                json.dump(losses, f)
            print(f"æå¤±è¨˜éŒ„å·²å„²å­˜è‡³: {save_path}")

    # è¨“ç·´çµæŸå¾Œå„²å­˜æœ€çµ‚æå¤±è¨˜éŒ„
    if save_path:
        with open(save_path, 'w') as f:
            json.dump(losses, f)
        print(f"æœ€çµ‚æå¤±è¨˜éŒ„å·²å„²å­˜è‡³: {save_path}")

    return losses

# ä¸»å‡½æ•¸
def main():
    print(f"ä½¿ç”¨è¨­å‚™: {device}")

    # åŠ è¼‰æ•¸æ“šé›†
    dataset = SimCLRDataset(root_dir=DATA_DIR, transform=contrast_transforms)
    dataloader = DataLoader(dataset, batch_size=BATCH_SIZE, shuffle=True, num_workers=NUM_WORKERS)
    print(f"æ•¸æ“šé›†å¤§å°: {len(dataset)}")

    # åˆå§‹åŒ–æ¨¡å‹ã€å„ªåŒ–å™¨èˆ‡æå¤±å‡½æ•¸
    model = SimCLRNet().to(device)
    optimizer = optim.Adam(model.parameters(), lr=LEARNING_RATE)
    criterion = NTXentLoss(temperature=TEMPERATURE)

    # ç¢ºä¿è¼¸å‡ºç›®éŒ„å­˜åœ¨
    if not os.path.exists(OUTPUT_DIR):
        os.makedirs(OUTPUT_DIR)

    # é–‹å§‹è¨“ç·´
    print("é–‹å§‹è¨“ç·´...")
    losses = train_self_supervised(model, dataloader, optimizer, criterion, device, epochs=EPOCHS, save_path=LOSSES_FILE)

    # å„²å­˜æ¨¡å‹
    torch.save(model.state_dict(), MODEL_SAVE_PATH)
    print("è¨“ç·´å®Œæˆï¼æ¨¡å‹å·²å„²å­˜")

if __name__ == "__main__":
    main()